{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_from_taiga(data_id, index_col = None):\n",
    "    '''Load dataset from taiga with caching.\n",
    "    INPUTS:\n",
    "        data_id: Unique ID of taiga dataset\n",
    "        index_col: column number to use as index\n",
    "    OUTPUTS:\n",
    "        loaded dataset as pandas df\n",
    "    '''\n",
    "    taiga_url = 'http://datasci-dev.broadinstitute.org:8999/rest/v0/datasets/'\n",
    "    data_dir = os.path.expanduser('~/.taiga') #directory for caching taiga files\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    data_file = os.path.join(data_dir,data_id + \".csv\")\n",
    "    data_source = taiga_url + data_id + \"?format=tabular_csv\"\n",
    "    if os.path.exists(data_file):\n",
    "        print('Loading ' + data_file + ' from disc')\n",
    "        data = pd.read_csv(data_file, header = 0)\n",
    "    else:\n",
    "        try:\n",
    "            print('Loading ' + data_source + ' from taiga')\n",
    "            data = pd.read_csv(data_source)\n",
    "        except:\n",
    "            print('Loading ' + data_source + ' from taiga')\n",
    "            data_source = taiga_url + data_id + \"?format=csv\"\n",
    "            data = pd.read_csv(data_source)\n",
    "\n",
    "        print('Saving to disc')\n",
    "        data.to_csv(data_file, index = False)   \n",
    "    if index_col is not None:\n",
    "        data.set_index(data.columns[index_col], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /root/.taiga/966b70bf-c414-43ad-97ec-1a8b50f91ed6.csv from disc\n",
      "Loading /root/.taiga/013458ff-bb36-4fd7-ac87-dcc04b15174e.csv from disc\n",
      "CLs: 478, Features: 18772, Targets: 5332\n"
     ]
    }
   ],
   "source": [
    "min_strong_deps = 5 #minimum number of < -2 sigma deps for using a gene\n",
    "\n",
    "dep_data_id = \"966b70bf-c414-43ad-97ec-1a8b50f91ed6\" #achilles-v2-20-1-demeter-z-scores-ignoring-expression-expanded-families- v2\n",
    "GE_data_id = \"013458ff-bb36-4fd7-ac87-dcc04b15174e\" # ccle-rnaseq-gene-expression-rpkm-for-analysis-in-manuscripts-protein-coding-genes-only-hgnc-mapped v3\n",
    "target_geneset_data_id = 'e714c26b-80c8-42b1-bb61-a88b7bb1b334' #target genes to be analyzed in depmap manuscript\n",
    "\n",
    "#grad datasets from taiga\n",
    "Dep = load_from_taiga(dep_data_id, index_col = 0).transpose()\n",
    "GE = load_from_taiga(GE_data_id, index_col = 0)\n",
    "\n",
    "#align GE and Dep data to common set of cell lines\n",
    "used_CLs = np.intersect1d(Dep.index.values, GE.index.values) \n",
    "Dep = Dep.ix[used_CLs]\n",
    "GE = GE.ix[used_CLs]\n",
    "\n",
    "#restrict target variables to those genes with at least min_strong_deps strong dependencies\n",
    "n_strong_deps = np.nansum(Dep < -2, axis = 0)\n",
    "Y_mat = Dep.values[:, n_strong_deps >= min_strong_deps].copy()\n",
    "\n",
    "X_mat = GE.values.copy()\n",
    "\n",
    "n_features = X_mat.shape[1] #number of predictors\n",
    "(n_CLs, n_targets) = Y_mat.shape \n",
    "\n",
    "print('CLs: {}, Features: {}, Targets: {}'.format(n_CLs, X_mat.shape[1], n_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_mtRidge(X, Y, l2_lambda = 0, verbose = True, force_fast = False):\n",
    "    '''Fit 'multi-task' ridge regression model\n",
    "    Inputs:\n",
    "        X: nxp matrix of predictors (no missing values alowed)\n",
    "        Y: nxq matrix of response variables (can have missing values)\n",
    "        l2_lambda: L2 regularization parameter\n",
    "        verbose: set to False to silence output\n",
    "        force_fast: set to True if you want to ignore the differing patterns of missing data in the columns of Y\n",
    "            This can be much faster if the patterns of missing data among columns of Y are highly variable.\n",
    "            It only gives an approximation to the ML solution though.\n",
    "    '''\n",
    "    #save y intersepts separately and then subtract them out\n",
    "    y_int = np.nanmean(Y, axis = 0)\n",
    "    Yc = Y.copy() - y_int\n",
    "\n",
    "    if force_fast:\n",
    "        #ignore differing patterns of missing values in the columns of Y\n",
    "        Yc[np.isnan(Yc)] = 0\n",
    "        U, s, Vt = linalg.svd(X, full_matrices=False)\n",
    "        idx = s > 1e-15  # same default value as scipy.linalg.pinv\n",
    "        s_nnz = s[idx][:, np.newaxis]\n",
    "        UTy = np.dot(U.T, Yc)\n",
    "\n",
    "        d = np.zeros((s.size, Yc.shape[1]))\n",
    "        d[idx] = s_nnz / (s_nnz ** 2 + l2_lambda)\n",
    "        d_UT_y = d * UTy\n",
    "        coefs = np.dot(Vt.T, d_UT_y) \n",
    "    else:\n",
    "        nan_sets = np.isnan(Yc)\n",
    "        nan_patterns = pd.DataFrame(nan_sets.T).drop_duplicates() #unique patterns of missing rows, over columns of Y\n",
    "        num_nan_patterns = nan_patterns.shape[0]\n",
    "        if verbose:\n",
    "            print('Found %d unique patterns of missing rows' % (num_nan_patterns))\n",
    "\n",
    "        coefs = np.ones((X.shape[1], Y.shape[1])) * np.nan \n",
    "        for idx, nan_pattern in enumerate(nan_patterns.values):\n",
    "            cur_cols = np.all(nan_sets == np.tile(nan_pattern, (nan_sets.shape[1],1)).T, axis = 0)\n",
    "            if verbose:\n",
    "                    print('Pattern %d/%d. Found %d/%d columns with %d/%d missing rows' % \\\n",
    "                      (idx+1, num_nan_patterns, np.sum(cur_cols), nan_sets.shape[1], \n",
    "                       np.sum(nan_pattern), nan_sets.shape[0]))\n",
    "            if np.sum(~nan_pattern) >= min_rows: #if there are enough usable rows\n",
    "                U, s, Vt = linalg.svd(X[~nan_pattern,:], full_matrices=False)\n",
    "                idx = s > 1e-15  # same default value as scipy.linalg.pinv\n",
    "                s_nnz = s[idx][:, np.newaxis]\n",
    "                d = np.zeros((s.size, Yc.shape[1]))\n",
    "                d[idx] = s_nnz / (s_nnz ** 2 + l2_lambda)\n",
    "                Y_sub = Yc[~nan_pattern,:]\n",
    "                UTy = np.dot(U.T, Y_sub[:, cur_cols])\n",
    "                d_UT_y = d[:, cur_cols] * UTy\n",
    "                coefs[:, cur_cols] = np.dot(Vt.T, d_UT_y) \n",
    "            elif verbose:\n",
    "                print('Not enough rows for this block')\n",
    "       \n",
    "    mod = {'coefs': coefs, 'y_int': y_int}\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 unique patterns of missing rows\n",
      "Pattern 1/5. Found 4261/5332 columns with 0/478 missing rows\n",
      "Pattern 2/5. Found 1037/5332 columns with 211/478 missing rows\n",
      "Pattern 3/5. Found 28/5332 columns with 19/478 missing rows\n",
      "Pattern 4/5. Found 4/5332 columns with 267/478 missing rows\n",
      "Pattern 5/5. Found 2/5332 columns with 192/478 missing rows\n",
      "CPU times: user 1min 28s, sys: 10.2 s, total: 1min 39s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mod = fit_mtRidge(X_mat, Y_mat, l2_lambda = 1000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
